---
title: "Final Project"
author: "Zane Brotherton, Nate Adam, Feolu Kolawole"
date: "2023-08-14"
output: pdf_document
---

# Project Description
```{r, message = FALSE}
set.seed(2158)
House_Data = read.table(url('https://raw.githubusercontent.com/zbrotherton2158/okadaStats/master/ames2000_NAfix.csv'), sep=',', header=T)
require(tidyverse)
require(corrplot)
require(dplyr)
library(car)
```


## The study

• What field does the data come from?

>This data comes from the field of real estate sales. The data came from the assessors office of Ames,  Iowa.
  
• What are the goals of the study? Are there any effects of particular interest?

>The purpose of this data is to be able to predict the value of a house in Ames Iowa. Our effects of    interest are the most statistically significant predictors, such as Overall Quality, Ground Living     Area, Roof Material and Neighborhood. 
  
• How might these goals be answered, i.e. tests / confidence intervals?

>This goal could be answered by the following procedure: 
 - Split the data into a testing and training set using a 50-50 split. 
 - Identify the most statisically significant predictors in the dataset. 
 - Train a linear model using these predictors based on the training partition of the set. 
 - Evaluate the fit of the model to the training data using $R^2$ and residual plots. 
 - Make any neccesary modifications such as removing outliers. 
 - Evaluate the model's performance on the training data using $R^2$ as a metric. 
 - Create confidence intervals for the most significant predictors' coefficient within the model.  
 
## The data
• How are the predictor variables spread out? Are there any noteworthy features to their spread
that could be highly influential observations?

>The variables consist of 23 nominal, 23 ordinal, 14 discrete, and 20 continuous predictors. Further analysis of the discrete variables found that some predictors, such as fireplaces, consist of a small range of values giving each individual value a greater influence over the final result. 

*Cleaning The Data*
```{r}
colums_to_replace = c()

for (j in 1:80){ 
  haveNumbers = c()
  for (i in 1:2000) {
    if (House_Data[i,j] == "") {
      House_Data[i,j] = "None"
    }
    haveNumbers = c(haveNumbers, !grepl("\\D", House_Data[i,j]))
  }
  if (any(haveNumbers) && (j != 59)) { 
    House_Data[j] = replace(House_Data[j], House_Data[j] == "None", 0)
    colums_to_replace = append(colums_to_replace, j)
  }
}

for(j in colums_to_replace){
  House_Data[, j] = as.numeric(House_Data[, j])
}
```

Based on our interpretation of the dataset, we replaced elements containing "None" with zero in columns for numerical predictors. 

*Factorizing Numerical Variables*
```{r}
House_Data$MS.SubClass = factor(House_Data$MS.SubClass)
House_Data$Overall.Qual = factor(House_Data$Overall.Qual)
House_Data$Overall.Cond = factor(House_Data$Overall.Cond)
```

We chose to factorize numerical variables that were marked as ordinal or nominal in the dataset description. 

*Investigate Numerical Predictors' Correlation with Sale Price*
```{r}
House_Data_Numerical = data.frame(select_if(House_Data, is.numeric))

Numerical_Correlations = cor(House_Data_Numerical, House_Data_Numerical$SalePrice)
print(Numerical_Correlations)
```

• Are any of the predictor variables highly correlated?

>The most significant numerical variables are `Gr. Living Area`, `Garage.Cars`, `Year Built`, `Year  Remodeled` and `Full Bath`.
  
*Correlation between Numerical Features*
```{r}
Numerical_Model_Features = data.frame(Living_Area = House_Data$Gr.Liv.Area, Year_Built = House_Data$Year.Built, Garage_Cars = House_Data$Garage.Cars, Year_Remodel = House_Data$Year.Remod.Add, Full_Bath = House_Data$Full.Bath)

corrplot(cor(Numerical_Model_Features), method = "number")
```

Using this correlation plot, we determined that none of the numerical predictors were unusually correlated with each other. 

*Identify Significant Categorical Variables*
```{r, message = FALSE, eval=FALSE}
House_Data_Categorical = data.frame(select_if(House_Data, negate(is.numeric)))
House_Data_Categorical$SalePrice = House_Data$SalePrice

investigative_lm = lm(SalePrice ~ ., data = subset(House_Data_Categorical, select = -c(Utilities)))
summary(investigative_lm)
confint(investigative_lm)
```

We built an investigative linear model using every categorical variable to predict `SalePrice`, and identified that the most statistically significant categorical variables are (measured in factors with p-value < 0.001), `Neighborhood` (4), `Condition.2` (1), `Bldg.Type` (3), `House.Style` (2), `Roof.Matl` (6), `Exter.Qual` (2), `BsmtFin.Type.1` (2), `Overall.Qual` (2), and `Kitchen.Qual` (3). 

## The model

• Which predictor variables, if any, should be included in the model a priori?

>The most statistically significant predictors should be included in the model a priori are Overall Quality, Ground Living Area, Building Type and Neighborhood. 

• Are there any interactions that should be considered for inclusion in the model?

  • 1st Flr Sf ~ Gr Liv Area (High Correlations)
  
  • Bsmt Full Bath ~ Full Bath (A Bsmt Full Bath counts for a Full Bath)
  
  • Bsmt Half Bath ~ Half Bath (A Bsmt Half Bath counts for a Half Bath)
  
  • Heating ~ HeatingQC (Affect each other)
  
  • BsmtFin Type 1 ~ Bsmt Type 2 (Existence of Type 2 depends on existence of Type 1)
  
  • Exterior 1 ~ Exterior 2 (Existence of 2 depends on existence of 1)
  
  • Kitchen ~ KitchenQual (If kitchen > grade, it will have a higher quality)
  
  • Garage Qual ~ Garage Cond (Quality depends on Conditions)

• Are there any three way interactions that should be considered?

  • 1st Flr Sf ~ 2nd Flr Sf ~ Gr Liv Area (1st Flr Sf and Gr Liv Area have high correlations)
  
  • BsmtFin Type 1 ~ Bsmt Type 2 ~ Bsmt Cond (Condition is influenced by the finishing)
  
  • Neighborhood ~ Condition 1 ~ Condition 2 (All related to physical location)
  
• Are there any interactions that should NOT be considered?

  • Full Bath ~ TotRmsAbvGrd (Does not include bathrooms)
  
  • Exter Qual ~ Exter Cond (Can have good quality materials in bad condition)
  
We added an interaction term for `Neighborhood` and `Condition.2`. 

*Partition the data*
```{r}
N = nrow(House_Data)
num_train = as.integer(0.5 * N)
train_idx = sample(1:N, size=num_train, replace=F)
test_idx = setdiff(1:N, train_idx)
House_Data_Train = House_Data[train_idx,]
House_Data_Test = House_Data[test_idx,]
```

We partitioned the data into a training set and a test set using a 50-50 split. 

## Results

*Model*
```{r}
par(mfrow=c(2,2))
model = lm(SalePrice ~ 
             #Numerical
             Garage.Cars + 
             Gr.Liv.Area +
             Year.Built +
             Year.Remod.Add +
             Full.Bath +
             #Categorical
             Overall.Qual +
             Neighborhood +
             Condition.2 +
             Neighborhood * Condition.2 +
             Bldg.Type +
             House.Style +
             Roof.Matl +
             Exter.Qual +
             BsmtFin.Type.1 +
             Kitchen.Qual
           , House_Data_Train)
summary(model)
plot(model)
```
• What is the final regression model for the data?
>The final regression model for the data is a linear regression model that predicts sale price using the most significant predictors.

*Model summary*
Observing the summary of the linear model, we can see that within context of our data, the median of the residuals is close to 0 at a value of 182, indicating the residuals are not skewed; additionally, the minimum and maximum and first quartile and third quartile are mostly symmetric, with the maximum being marginally asymmetric. Our linear model resulted in a $R^2$ value of 0.91 on the training set and an adjusted $R^2$ value of 0.90. The models p value for its F-statistic, < 2.2e-16, indicates that the model as a whole is statistically significant. 

*Diagnostic plots*
  • While observing the residuals vs leverage plot, we noticed that there are some outliers present,       but no outliers have an unusually high cook's distance. 

  • While observing the residuals vs fitted plot, it didn't seem as though the model exhibits              heteroskedasticity. Additionally, the fact that we observe and equal amount of residuals above and     below the line provides evidence against any possibility of non-linearity. 
  
  • Analyzing the scale location plot, further evidence is provided that there is no                       heteroskedasticity, due to the residuals' constant variance around the trend line, which does not      exhibit a steep slope. 
  
  • Using the standard diagnostic tests, does the model appear to fit the data well?
  > Using these diagnostic metrics, the model appears to fit the data well. 
  
*VIF of Predictor Variables*
```{r}
vifs = vif(model)
print(vifs)
```

We used a variance influence factor test to check our predictor variables for collinearity, during this test we found `PoolQC` and `Roof.Matl` to be near perfectly correlated with each other. This near perfect collinearity of two variables that are not intuitively correlated was due to `PoolQC` being filled with mostly "none" values, and `Roof.Matl` being filled with the same "CompShg" value, making these variables seem as though a "CompShg" in `Roof.Matl` was correlated with a "None" in `PoolQC`. We decided to drop `PoolQC` because the "None" values had little to no significance. Aside from this, we determined that all other variables showed an acceptable level of collinearity. 

*Confidence Intervals*

• What are the final confidence intervals for the effects of interest mentioned in the study section?

```{r}

relevant_predictors = c(
  "Gr.Liv.Area",
  "Year.Built",
  "Year.Remod.Add",
  "Full.Bath",
  "Garage.Cars"
)

confint(model, relevant_predictors)
```
  
These are confidence intervals for the coefficents of our numerical variables. 

• Use your validation data to construct these intervals. Do these intervals seem very sensitive to the
choice of model (i.e. do they vary widely for different choices of variables in the model)?
>Yes, these intervals do seem sensitive to the choice of model, as they changed drastically when computed on the investigative model versus the final model. 

*Drop Levels not Present in Training Data*
```{r}
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Condition.2=="RRAn",])
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Roof.Matl=="ClyTile",])
```

We had to drop some levels from the testing data that were not present in the training data. 

• What is your estimated prediction accuracy for your model? (Evaluated on the validation set).

*Calculate $R^2$ on Testing Data*
```{r}
plot(House_Data_Test$SalePrice, predict(model, newdata = House_Data_Test, type = "response"))
r2 = 1 - (sum((House_Data_Test$SalePrice - predict(model, newdata = House_Data_Test, type = "response")) ^ 2)
          /sum((House_Data_Test$SalePrice - mean(House_Data_Test$SalePrice)) ^ 2))
print(r2)
```
We found that the $R^2$ value is equal to ~0.88 for the testing data, which indicates that our model performs successfully and was not overfit to the training data. 

• Compare the intervals constructed using your final selected model fit to the validation set to the
same intervals constructed on the training set. Are they very different? Which do you believe
more?

## Acknowledgements

In: Stanford University. http://web.stanford.edu/class/stats191/data/amesdoc.txt. Accessed 14 Aug 2023
  

