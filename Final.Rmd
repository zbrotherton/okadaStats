---
title: "Final Project"
author: "Zane Brotherton, Nate Adam, Feolu Kolawole"
date: "2023-08-14"
output: pdf_document
---

# Project Description
```{r, message = FALSE}
set.seed(2158)
House_Data = read.table(url('https://raw.githubusercontent.com/zbrotherton2158/okadaStats/master/ames2000_NAfix.csv'), sep=',', header=T)
require(tidyverse)
require(corrplot)
require(dplyr)
library(car)
```


## The study

• What field does the data come from?

>This data comes from the field of real estate sales. The data came from the assessors office of Ames,  Iowa.
  
• What are the goals of the study? Are there any effects of particular interest?

>The purpose of this data is to be able to predict the value of a house in Ames Iowa. Our effects of    interest are the most statistically significant predictors, such as Overall Quality, Ground Living     Area, Roof Material and Neighborhood. 
  
• How might these goals be answered, i.e. tests / confidence intervals?

>This goal could be answered by the following procedure: 
 - Split the data into a testing and training set using a 50-50 split. 
 - Identify the most statisically significant predictors in the dataset. 
 - Train a linear model using these predictors based on the training partition of the set. 
 - Evaluate the fit of the model to the training data using $R^2$ and residual plots. 
 - Make any neccesary modifications such as removing outliers. 
 - Evaluate the model's performance on the training data using $R^2$ as a metric. 
 - Create confidence intervals for the most significant predictors' coefficient within the model.  
 
## The data
• How are the predictor variables spread out? Are there any noteworthy features to their spread
that could be highly influential observations?

>The variables consist of 23 nominal, 23 ordinal, 14 discrete, and 20 continuous predictors. Further analysis of the discrete variables found that some predictors, such as fireplaces, consist of a small range of values giving each individual value a greater influence over the final result. 

*Cleaning The Data*
```{r}
colums_to_replace = c()

for (j in 1:80){ 
  haveNumbers = c()
  for (i in 1:2000) {
    if (House_Data[i,j] == "") {
      House_Data[i,j] = "None"
    }
    haveNumbers = c(haveNumbers, !grepl("\\D", House_Data[i,j]))
  }
  if (any(haveNumbers) && (j != 59)) { 
    House_Data[j] = replace(House_Data[j], House_Data[j] == "None", 0)
    colums_to_replace = append(colums_to_replace, j)
  }
}

for(j in colums_to_replace){
  House_Data[, j] = as.numeric(House_Data[, j])
}
```

Based on our interpretation of the dataset, we replaced elements containing "None" with zero in columns for numerical predictors. 

*Factorizing Numerical Variables*
```{r}
House_Data$MS.SubClass = factor(House_Data$MS.SubClass)
House_Data$Overall.Qual = factor(House_Data$Overall.Qual)
House_Data$Overall.Cond = factor(House_Data$Overall.Cond)
```

We chose to factorize numerical variables that were marked as ordinal or nominal in the dataset description. 

*Investigate Numerical Predictors' Correlation with Sale Price*
```{r}
House_Data_Numerical = data.frame(select_if(House_Data, is.numeric))

Numerical_Correlations = cor(House_Data_Numerical, House_Data_Numerical$SalePrice)
print(Numerical_Correlations)
```

• Are any of the predictor variables highly correlated?

>The most significant numerical variables are `Gr. Living Area`, `Garage.Cars`, `Year Built`, `Year  Remodeled` and `Full Bath`.
  
*Correlation between Numerical Features*
```{r}
Numerical_Model_Features = data.frame(Living_Area = House_Data$Gr.Liv.Area, Year_Built = House_Data$Year.Built, Garage_Cars = House_Data$Garage.Cars, Year_Remodel = House_Data$Year.Remod.Add, Full_Bath = House_Data$Full.Bath)

corrplot(cor(Numerical_Model_Features), method = "number")
```

Using this correlation plot, we determined that none of the numerical predictors were unusually correlated with each other. 

*Identify Significant Categorical Variables*
```{r, message = FALSE, eval=FALSE}
House_Data_Categorical = data.frame(select_if(House_Data, negate(is.numeric)))
House_Data_Categorical$SalePrice = House_Data$SalePrice

investigative_lm = lm(SalePrice ~ ., data = subset(House_Data_Categorical, select = -c(Utilities)))
summary(investigative_lm)
```

We built an investigative linear model using every categorical variable to predict `SalePrice`, and identified that the most statistically significant categorical variables are (measured in factors with p-value < 0.001), `Neighborhood` (4), `Condition.2` (1), `Bldg.Type` (3), `House.Style` (2), `Roof.Matl` (6), `Exter.Qual` (2), `BsmtFin.Type.1` (2), `Overall.Qual` (2), and `Kitchen.Qual` (3). 

## The model

• Which predictor variables, if any, should be included in the model a priori?

>The most statistically significant predictors should be included in the model a priori are Overall Quality, Ground Living Area, Building Type and Neighborhood. 

*Partition the data*
```{r}
N = nrow(House_Data)
num_train = as.integer(0.5 * N)
train_idx = sample(1:N, size=num_train, replace=F)
test_idx = setdiff(1:N, train_idx)
House_Data_Train = House_Data[train_idx,]
House_Data_Test = House_Data[test_idx,]
```

We partitioned the data into a training set and a test set using a 50-50 split. 

*Model*
```{r}
par(mfrow=c(2,2))
model = lm(SalePrice ~ 
             #Numerical
             Garage.Cars + 
             Gr.Liv.Area +
             Year.Built +
             Year.Remod.Add +
             Full.Bath +
             #Categorical
             Overall.Qual +
             Neighborhood +
             Condition.2 +
             Bldg.Type +
             House.Style +
             Roof.Matl +
             Exter.Qual +
             BsmtFin.Type.1 +
             Kitchen.Qual
           , House_Data_Train)
summary(model)
plot(model)
```

Based off the predictors we previously found to be the most significant, we made a linear model. 

```{r}
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Condition.2=="RRAn",])
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Roof.Matl=="ClyTile",])
#House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Full.Bath=="4",])
plot(House_Data_Test$SalePrice, predict(model, newdata = House_Data_Test, type = "response"))
r2 = 1 - (sum((House_Data_Test$SalePrice - predict(model, newdata = House_Data_Test, type = "response")) ^ 2)
          /sum((House_Data_Test$SalePrice - mean(House_Data_Test$SalePrice)) ^ 2))
print(r2)
```

```{r}

outlier_rows_train = c(1542, 581, 1325, 503, 813, 1993, 652, 1836, 368, 1328, 583, 165, 934, 18, 1505, 687, 535, 1273, 1643)

outlier_rows_removal = c()

for(val in outlier_rows_train){
  for(num in 1 : nrow(House_Data_Train)){
    if(identical(House_Data_Train[num, ], House_Data[val, ])){
      outlier_rows_removal = append(outlier_rows_removal, num)
    }
  }
}

House_Data_No_Outliers = House_Data_Train[ -outlier_rows_removal, ]

#factorize these?
model_no_outliers = lm(SalePrice ~ 
             #Numerical
             Overall.Qual +
             Gr.Liv.Area +
             Year.Built +
             Year.Remod.Add +
             Full.Bath +
             #Categorical
             Neighborhood +
             Condition.1 +
             Condition.2 +
             Bldg.Type +
             House.Style +
             Roof.Matl +
             Exter.Qual +
             BsmtFin.Type.1 +
             Kitchen.Qual +
             Fireplace.Qu +
             Garage.Type
           , House_Data_No_Outliers)
summary(model_no_outliers)
plot(model_no_outliers)


```




*VIF of Predictor Variables*
```{r}

vifs = vif(model)
print(vifs)
```

*Confidence Intervals*
```{r}

relevant_predictors = c(
  "Overall.Qual",
  "Gr.Liv.Area",
  "Year.Built",
  "Year.Remod.Add",
  "Full.Bath"
)

confint(model, relevant_predictors)
```

### Analysis
R^2 of testing set
```{r}
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Condition.2=="RRAn",])
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Roof.Matl=="ClyTile",])
#House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Full.Bath=="4",])
plot(House_Data_Test$SalePrice, predict(model_no_outliers, newdata = House_Data_Test, type = "response"))
r2 = 1 - (sum((House_Data_Test$SalePrice - predict(model_no_outliers, newdata = House_Data_Test, type = "response")) ^ 2)
          /sum((House_Data_Test$SalePrice - mean(House_Data_Test$SalePrice)) ^ 2))
print(r2)
```



• Are there any interactions that should be considered for inclusion in the model?

  • 1st Flr Sf ~ Gr Liv Area (High Correlations)
  
  • Bsmt Full Bath ~ Full Bath (A Bsmt Full Bath counts for a Full Bath)
  
  • Bsmt Half Bath ~ Half Bath (A Bsmt Half Bath counts for a Half Bath)
  
  • Heating ~ HeatingQC (Affect each other)
  
  • BsmtFin Type 1 ~ Bsmt Type 2 (Existence of Type 2 depends on existence of Type 1)
  
  • Exterior 1 ~ Exterior 2 (Existence of 2 depends on existence of 1)
  
  • Kitchen ~ KitchenQual (If kitchen > grade, it will have a higher quality)
  
  • Garage Qual ~ Garage Cond (Quality depends on Conditions)


• Are there any three way interactions that should be considered?

  • 1st Flr Sf ~ 2nd Flr Sf ~ Gr Liv Area (1st Flr Sf and Gr Liv Area have high correlations)
  
  • BsmtFin Type 1 ~ Bsmt Type 2 ~ Bsmt Cond (Condition is influenced by the finishing)
  
  • Neighborhood ~ Condition 1 ~ Condition 2 (All related to physical location)
  
  
• Are there any interactions that should NOT be considered?

  • Full Bath ~ TotRmsAbvGrd (Does not include bathrooms)
  
  • Exter Qual ~ Exter Cond (Can have good quality materials in bad condition)
  
Pool Quality and Roof Material were highly correlated with each other, running a variance inflation factor gave us an error signifying collinearity between 2 variables, which we found to be Pool Quality and Roof Material. 

Error Given: ~There are aliased coefficients in the model.

  
## Results

*Results*: In this section, you should report the results obtained by fitting the proposed models in the
previous section. Emphasis should be placed on clarity, as if the report were a statistical consultant’s
report for a nonstatistician. For instance, loads of R output would, in general, not be acceptable. Plots
and well-organized tables are good things to have in this section. Possible questions to be addressed
here are the following:
• What is the final regression model for the data?

• Using the standard diagnostic tests, does the model appear to fit the data well?

• What are the final confidence intervals for the effects of interest mentioned in the study section?

  • 
  

Use your validation data to construct these intervals. Do these intervals seem very sensitive to the
choice of model (i.e. do they vary widely for different choices of variables in the model)?

• What is your estimated prediction accuracy for your model? (Evaluated on the validation set).

• Compare the intervals constructed using your final selected model fit to the validation set to the
same intervals constructed on the training set. Are they very different? Which do you believe
more?


## Acknowledgements

In: Stanford University. http://web.stanford.edu/class/stats191/data/amesdoc.txt. Accessed 14 Aug 2023
  

