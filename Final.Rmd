---
title: "Final Project"
author: "Zane Brotherton, Nate Adam, Feolu Kolawole"
date: "2023-08-14"
output: pdf_document
---

# Project Description

```{r}
set.seed(2158)
House_Data = read.table(url('https://raw.githubusercontent.com/zbrotherton2158/okadaStats/master/ames2000_NAfix.csv'), sep=',', header=T)
```

## The study
• What field does the data come from?
  This data comes from the assessors office of Ames, Iowa
• What are the goals of the study? Are there any effects of particular interest?
  The purpose of this data is to be able to predict the value of a house in Ames Iowa
  Our areas of interest are the effect of the neighborhoods, lot area, total rooms above grade, year built, and total square feet on the price of the house. 
• How might these goals be answered, i.e. tests / confidence intervals?
  This goal could be answered by a prediction model that, given information about a house, will output a 95% confidence interval predicting the price of the house.

## The data
### Predictor Variable Spread
```{r}
require(tidyverse)
Numerical_Count = length(select_if(House_Data, is.numeric))
Categorical_Count = length(select_if(House_Data, negate(is.numeric)))

```

```{r}
#to investigate numerical variables
House_Data_Numerical = data.frame(select_if(House_Data, is.numeric))
```

### Correlation Info
*Numerical Correlation*
```{r}
require(corrplot)
require(dplyr)

Numerical_Correlations = cor(House_Data_Numerical, House_Data_Numerical$SalePrice)
print(Numerical_Correlations)
```

*Correlation between Numerical Features*
```{r}

Numerical_Model_Features = data.frame(Overall_Quality = House_Data$Overall.Qual, Living_Area = House_Data$Gr.Liv.Area, Year_Built = House_Data$Year.Built, Year_Remodel = House_Data$Year.Remod.Add, Full_Bath = House_Data$Full.Bath)


corrplot(cor(Numerical_Model_Features), method = "number")

```

### Analysis
• How are the predictor variables spread out? Are there any noteworthy features to their spread
that could be highly influential observations?

The variables are seemingly random between discrete, ordinal, nominal, and continuous types of variables. Of these, we found 26 to be numerical and 54 categorical. Within the discrete variables, variables with a spread like fireplaces where despite being numerical only have values of 1 - arbitrarily small number may have a higher effect on the price per unit increase. 

• Are any of the predictor variables highly correlated?

  The highest correlation numerical variables are:
  
  • Overall Quality (~0.805)
  
  • Gr. Living Area (~0.720)
  
  • Year Built (~0.57)
  
  • Full Bath (~0.561)
  
  • Year Remodeled (~0.535)
  
  • Rooms Above Ground (~0.504)
  
  • Fireplace (~0.48)
  
  • 1st Floor Square Ft. (~0.619)
  
  • 2nd Floor Square Ft. (~0.295)*
  
  The most statistically significant categorical variables are:
  
  • Overall.Qual (|t|<2e-16)
  
  • Gr.Liv.Area (|t|<2e-16)
  
  • Year.Built (|t|<9.05e-15)
  
  • Year.Remod.Add (|t|<1.01e-06)
  
  • Neighborhood (|t|<??)
  
  • Condition.2 (|t|<??)
  
  • Bldg.Type (|t|<??)
  
  
## The models
*Clean "none" values*
```{r}

# NOTE: Might have to revamp
# Turned Nones into 0's for respective rows
# Filled Empty boxes with "None" for categorical variables. 

for (j in 1:80){ 
  haveNumbers = c()
  for (i in 1:2000) {
    if (House_Data[i,j] == "") {
      House_Data[i,j] = "None"
    }
    haveNumbers = c(haveNumbers, !grepl("\\D", House_Data[i,j]))
  }
  if (any(haveNumbers) && (j != 59)) { 
    House_Data[j] = replace(House_Data[j], House_Data[j] == "None", 0)
  }
}

```

*Analyzing categories*
```{r}
#to investigate categories
library(tidyverse)
House_Data_Categorical = data.frame(select_if(House_Data, negate(is.numeric)))
House_Data_Categorical$SalePrice = House_Data$SalePrice

boxplot(House_Data$SalePrice ~ House_Data$Full.Bath)

sapply(lapply(House_Data_Categorical, unique), length)

investigative_lm = lm(SalePrice ~ ., data = subset(House_Data_Categorical, 
select = -c(Utilities,Lot.Frontage,Mas.Vnr.Area,BsmtFin.SF.1,BsmtFin.SF.2,Bsmt.Unf.SF,Total.Bsmt.SF,Garage.Yr.Blt,Garage.Area)))
summary(investigative_lm)

```

*Factorizing Discrete Variables*
```{r}
House_Data$MS.SubClass = factor(House_Data$MS.SubClass)
House_Data$Overall.Qual = factor(House_Data$Overall.Qual)
House_Data$Overall.Cond = factor(House_Data$Overall.Cond)
```

*Partition the data*
```{r}
N = nrow(House_Data)
num_train = as.integer(0.5 * N)
train_idx = sample(1:N, size=num_train, replace=F)
test_idx = setdiff(1:N, train_idx)
House_Data_Train = House_Data[train_idx,]
House_Data_Test = House_Data[test_idx,]
```

*Model Draft*
```{r}

#factorize these?
model = lm(SalePrice ~ 
             #Numerical
             Overall.Qual +
             Gr.Liv.Area +
             Year.Built +
             Year.Remod.Add +
             Full.Bath +
             #Categorical
             Neighborhood +
             Condition.1 +
             Condition.2 +
             Bldg.Type +
             House.Style +
             Roof.Matl +
             Exter.Qual +
             BsmtFin.Type.1 +
             Kitchen.Qual +
             Fireplace.Qu +
             Garage.Type
           , House_Data_Train)
summary(model)
plot(model)

```

```{r}
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Condition.2=="RRAn",])
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Roof.Matl=="ClyTile",])
#House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Full.Bath=="4",])
plot(House_Data_Test$SalePrice, predict(model, newdata = House_Data_Test, type = "response"))
r2 = 1 - (sum((House_Data_Test$SalePrice - predict(model, newdata = House_Data_Test, type = "response")) ^ 2)
          /sum((House_Data_Test$SalePrice - mean(House_Data_Test$SalePrice)) ^ 2))
print(r2)
```

```{r}

outlier_rows_train = c(1542, 581, 1325, 503, 813, 1993, 652, 1836, 368, 1328, 583, 165, 934, 18, 1505, 687, 535, 1273, 1643)

outlier_rows_removal = c()

for(val in outlier_rows_train){
  for(num in 1 : nrow(House_Data_Train)){
    if(identical(House_Data_Train[num, ], House_Data[val, ])){
      outlier_rows_removal = append(outlier_rows_removal, num)
    }
  }
}

House_Data_No_Outliers = House_Data_Train[ -outlier_rows_removal, ]

#factorize these?
model_no_outliers = lm(SalePrice ~ 
             #Numerical
             Overall.Qual +
             Gr.Liv.Area +
             Year.Built +
             Year.Remod.Add +
             Full.Bath +
             #Categorical
             Neighborhood +
             Condition.1 +
             Condition.2 +
             Bldg.Type +
             House.Style +
             Roof.Matl +
             Exter.Qual +
             BsmtFin.Type.1 +
             Kitchen.Qual +
             Fireplace.Qu +
             Garage.Type
           , House_Data_No_Outliers)
summary(model_no_outliers)
plot(model_no_outliers)


```




*VIF of Predictor Variables*
```{r}
library(car)
vifs = vif(model)
print(vifs)
```

*Confidence Intervals*
```{r}

relevant_predictors = c(
  "Overall.Qual",
  "Gr.Liv.Area",
  "Year.Built",
  "Year.Remod.Add",
  "Full.Bath"
)

confint(model, relevant_predictors)
```

### Analysis
R^2 of testing set
```{r}
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Condition.2=="RRAn",])
House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Roof.Matl=="ClyTile",])
#House_Data_Test <- droplevels(House_Data_Test[!House_Data_Test$Full.Bath=="4",])
plot(House_Data_Test$SalePrice, predict(model_no_outliers, newdata = House_Data_Test, type = "response"))
r2 = 1 - (sum((House_Data_Test$SalePrice - predict(model_no_outliers, newdata = House_Data_Test, type = "response")) ^ 2)
          /sum((House_Data_Test$SalePrice - mean(House_Data_Test$SalePrice)) ^ 2))
print(r2)
```

• Which predictor variables, if any, should be included in the model a-priority?

The highest correlation numerical variables and most statistically significant categorical listed under "The Data" are of the most interest and are the most prioritized in the model. (Neighborhoods, lot area, total rooms above grade, year built, and total square feet etc.)

• Are there any interactions that should be considered for inclusion in the model?

  • 1st Flr Sf ~ Gr Liv Area (High Correlations)
  
  • Bsmt Full Bath ~ Full Bath (A Bsmt Full Bath counts for a Full Bath)
  
  • Bsmt Half Bath ~ Half Bath (A Bsmt Half Bath counts for a Half Bath)
  
  • Heating ~ HeatingQC (Affect each other)
  
  • BsmtFin Type 1 ~ Bsmt Type 2 (Existence of Type 2 depends on existence of Type 1)
  
  • Exterior 1 ~ Exterior 2 (Existence of 2 depends on existence of 1)
  
  • Kitchen ~ KitchenQual (If kitchen > grade, it will have a higher quality)
  
  • Garage Qual ~ Garage Cond (Quality depends on Conditions)


• Are there any three way interactions that should be considered?

  • 1st Flr Sf ~ 2nd Flr Sf ~ Gr Liv Area (1st Flr Sf and Gr Liv Area have high correlations)
  
  • BsmtFin Type 1 ~ Bsmt Type 2 ~ Bsmt Cond (Condition is influenced by the finishing)
  
  • Neighborhood ~ Condition 1 ~ Condition 2 (All related to physical location)
  
  
• Are there any interactions that should NOT be considered?

  • Full Bath ~ TotRmsAbvGrd (Does not include bathrooms)
  
  • Exter Qual ~ Exter Cond (Can have good quality materials in bad condition)
  
Pool Quality and Roof Material were highly correlated with each other, running a variance inflation factor gave us an error signifying collinearity between 2 variables, which we found to be Pool Quality and Roof Material. 

Error Given: ~There are aliased coefficients in the model.

  
## Results

*Results*: In this section, you should report the results obtained by fitting the proposed models in the
previous section. Emphasis should be placed on clarity, as if the report were a statistical consultant’s
report for a nonstatistician. For instance, loads of R output would, in general, not be acceptable. Plots
and well-organized tables are good things to have in this section. Possible questions to be addressed
here are the following:
• What is the final regression model for the data?

• Using the standard diagnostic tests, does the model appear to fit the data well?

• What are the final confidence intervals for the effects of interest mentioned in the study section?

  • 
  

Use your validation data to construct these intervals. Do these intervals seem very sensitive to the
choice of model (i.e. do they vary widely for different choices of variables in the model)?

• What is your estimated prediction accuracy for your model? (Evaluated on the validation set).

• Compare the intervals constructed using your final selected model fit to the validation set to the
same intervals constructed on the training set. Are they very different? Which do you believe
more?


## Acknowledgements

  In: Stanford University. http://web.stanford.edu/class/stats191/data/amesdoc.txt. Accessed 14 Aug 2023
  
  
Questions: 
Why did the example slide drop Crim in the example slides.

